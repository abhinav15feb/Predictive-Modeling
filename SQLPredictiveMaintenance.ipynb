{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Step 1: Conver datetime feild to_datetime for all datafiles\n",
    "Step 2: Merge Machines data to telemetry data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow, keras\n",
    "import pandas\n",
    "import numpy\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers import Dense, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#errors = pandas.read_csv('/Users/abhi/Desktop/Sem 4/BNAD/SQL-Server-R-Services-Samples/PredictiveMaintanenceModelingGuide/Data/errors.csv')\n",
    "#failures = pandas.read_csv('/Users/abhi/Desktop/Sem 4/BNAD/SQL-Server-R-Services-Samples/PredictiveMaintanenceModelingGuide/Data/failures.csv')\n",
    "#machines = pandas.read_csv('/Users/abhi/Desktop/Sem 4/BNAD/SQL-Server-R-Services-Samples/PredictiveMaintanenceModelingGuide/Data/machines.csv')\n",
    "maintain = pandas.read_csv('/Users/abhi/Desktop/Sem 4/BNAD/SQL-Server-R-Services-Samples/PredictiveMaintanenceModelingGuide/Data/maint.csv')\n",
    "telemetry = pandas.read_csv('/Users/abhi/Desktop/Sem 4/BNAD/SQL-Server-R-Services-Samples/PredictiveMaintanenceModelingGuide/Data/telemetry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors['datetime']=pandas.to_datetime(errors['datetime'])\n",
    "telemetry['datetime']=pandas.to_datetime(telemetry['datetime'])\n",
    "maintain['datetime']=pandas.to_datetime(maintain['datetime'])\n",
    "failures['datetime']=pandas.to_datetime(failures['datetime'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maintain pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comp4 = maintain.iloc[numpy.where(maintain['comp']=='comp4')]\n",
    "comp3 = maintain.iloc[numpy.where(maintain['comp']=='comp3')]\n",
    "comp2 = maintain.iloc[numpy.where(maintain['comp']=='comp2')]\n",
    "comp1 = maintain.iloc[numpy.where(maintain['comp']=='comp1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintain_pivot_t = (pandas.merge(comp4, comp3, on = ['datetime', 'machineID'], how = 'outer'))\n",
    "maintain_pivot_t = maintain_pivot_t.rename(columns={maintain_pivot_t.columns[2]:'comp4', maintain_pivot_t.columns[3]:'comp3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintain_pivot_t2= pandas.merge(maintain_pivot_t, comp2, on = ['datetime', 'machineID'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintain_pivot= pandas.merge(maintain_pivot_t2, comp1, on = ['datetime', 'machineID'], how = 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maintain_pivot.rename(columns={maintain_pivot.columns[2]:'comp4', maintain_pivot.columns[3]:'comp3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maintain_pivot = maintain_pivot.fillna(0)\n",
    "maintain_pivot.loc[maintain_pivot['comp1'] == 'comp1', 'comp1'] = 1\n",
    "maintain_pivot.loc[maintain_pivot['comp2'] == 'comp2', 'comp2'] = 1\n",
    "maintain_pivot.loc[maintain_pivot['comp3'] == 'comp3', 'comp3'] = 1\n",
    "maintain_pivot.loc[maintain_pivot['comp4'] == 'comp4', 'comp4'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maintain_pivot = maintain_pivot.rename(columns={maintain_pivot.columns[2]:'Mantain_comp4',maintain_pivot.columns[3]:'Mantain_comp3',maintain_pivot.columns[4]:'Mantain_comp2', maintain_pivot.columns[5]:'Mantain_comp1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "maintain_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error4 = errors.iloc[numpy.where(errors['errorID']=='error4')]\n",
    "error3 = errors.iloc[numpy.where(errors['errorID']=='error3')]\n",
    "error2 = errors.iloc[numpy.where(errors['errorID']=='error2')]\n",
    "error1 = errors.iloc[numpy.where(errors['errorID']=='error1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors_pivot_t = (pandas.merge(error4, error3, on = ['datetime', 'machineID'], how = 'outer'))\n",
    "errors_pivot_t = errors_pivot_t.rename(columns={errors_pivot_t.columns[2]:'error4', errors_pivot_t.columns[3]:'error3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_pivot_t2= pandas.merge(errors_pivot_t, error2, on = ['datetime', 'machineID'], how = 'outer')\n",
    "errors_pivot= pandas.merge(errors_pivot_t2, error1, on = ['datetime', 'machineID'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_pivot = errors_pivot.rename(columns={errors_pivot.columns[4]:'error2', errors_pivot.columns[5]:'error1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors_pivot = errors_pivot.fillna(0)\n",
    "errors_pivot.loc[errors_pivot['error1'] == 'error1', 'error1'] = 1\n",
    "errors_pivot.loc[errors_pivot['error2'] == 'error2', 'error2'] = 1\n",
    "errors_pivot.loc[errors_pivot['error3'] == 'error3', 'error3'] = 1\n",
    "errors_pivot.loc[errors_pivot['error4'] == 'error4', 'error4'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(errors_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# failures Pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp4 = failures.iloc[numpy.where(failures['failure']=='comp4')]\n",
    "comp3 = failures.iloc[numpy.where(failures['failure']=='comp3')]\n",
    "comp2 = failures.iloc[numpy.where(failures['failure']=='comp2')]\n",
    "comp1 = failures.iloc[numpy.where(failures['failure']=='comp1')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_pivot_t = (pandas.merge(comp4, comp3, on = ['datetime', 'machineID'], how = 'outer'))\n",
    "failures_pivot_t = failures_pivot_t.rename(columns={failures_pivot_t.columns[2]:'comp4', failures_pivot_t.columns[3]:'comp3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_pivot_t2= pandas.merge(failures_pivot_t, comp2, on = ['datetime', 'machineID'], how = 'outer')\n",
    "failures_pivot= pandas.merge(failures_pivot_t2, comp1, on = ['datetime', 'machineID'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_pivot = failures_pivot.rename(columns={failures_pivot.columns[4]:'comp2', failures_pivot.columns[5]:'comp1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failures_pivot = failures_pivot.fillna(0)\n",
    "failures_pivot.loc[failures_pivot['comp1'] == 'comp1', 'comp1'] = 1\n",
    "failures_pivot.loc[failures_pivot['comp2'] == 'comp2', 'comp2'] = 1\n",
    "failures_pivot.loc[failures_pivot['comp3'] == 'comp3', 'comp3'] = 1\n",
    "failures_pivot.loc[failures_pivot['comp4'] == 'comp4', 'comp4'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failures_pivot = failures_pivot.rename(columns={failures_pivot.columns[2]:'fail_comp4',failures_pivot.columns[3]:'fail_comp3',failures_pivot.columns[4]:'fail_comp2', failures_pivot.columns[5]:'fail_comp1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "failures_pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data combining process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata = pandas.merge(telemetry, machines, on = ['machineID'], how = 'outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fulldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata1 = pandas.merge(fulldata, errors_pivot, on = ['datetime','machineID'], how = 'outer')\n",
    "fulldata2 = pandas.merge(fulldata1, maintain_pivot, on = ['datetime','machineID'], how = 'outer')\n",
    "fulldata3 = pandas.merge(fulldata2, failures_pivot, on = ['datetime','machineID'], how = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata3 = fulldata3.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (telemetry.count())\n",
    "print (errors.count())\n",
    "print (maintain.count())\n",
    "print (failures.count())\n",
    "print(fulldata3.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulldata3.to_csv('final_sql_data.csv', sep = ',',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read data and continue building Remaining Useful Life feature for failure and maintenance prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = pandas.read_csv('final_sql_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process -\n",
    "1. Add remaining useful life\n",
    "   if failure exists and last maintenance exist or assume start of time ie first entry of data for perticular machine in telemetry\n",
    "   Failure of component - Last Maintenance of component\n",
    "2. generate label columns for training data\n",
    "   we will only make use of \"label1\" for binary classification, \n",
    "   while trying to answer the question: is a specific engine going to fail within w1 cycles?\n",
    "   w1 = 30\n",
    "    w0 = 15\n",
    "    train_df['label1'] = np.where(train_df['RUL'] <= w1, 1, 0 )\n",
    "    train_df['label2'] = train_df['label1']\n",
    "    train_df.loc[train_df['RUL'] <= w0, 'label2'] = 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.sort_values('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data['DateTillMaintain_comp1'] =final_data[(final_data['Mantain_comp1']==1)].datetime\n",
    "final_data['DateTillMaintain_comp2'] =final_data[(final_data['Mantain_comp2']==1)].datetime\n",
    "final_data['DateTillMaintain_comp3'] =final_data[(final_data['Mantain_comp3']==1)].datetime\n",
    "final_data['DateTillMaintain_comp4'] =final_data[(final_data['Mantain_comp4']==1)].datetime\n",
    "\n",
    "final_data['DateTillFailure_comp1'] =final_data[(final_data['fail_comp1']==1)].datetime\n",
    "final_data['DateTillFailure_comp2'] =final_data[(final_data['fail_comp2']==1)].datetime\n",
    "final_data['DateTillFailure_comp3'] =final_data[(final_data['fail_comp3']==1)].datetime\n",
    "final_data['DateTillFailure_comp4'] =final_data[(final_data['fail_comp4']==1)].datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = final_data.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "final_data ['RULtillFail_comp1'] = (pandas.to_datetime(final_data['DateTillFailure_comp1'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "final_data ['RULtillFail_comp2'] = (pandas.to_datetime(final_data['DateTillFailure_comp2'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "final_data ['RULtillFail_comp3'] = (pandas.to_datetime(final_data['DateTillFailure_comp3'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "final_data ['RULtillFail_comp4'] = (pandas.to_datetime(final_data['DateTillFailure_comp4'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "\n",
    "final_data ['RULtillMaintain_comp1'] = (pandas.to_datetime(final_data['DateTillMaintain_comp1'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "final_data ['RULtillMaintain_comp2'] = (pandas.to_datetime(final_data['DateTillMaintain_comp2'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "final_data ['RULtillMaintain_comp3'] = (pandas.to_datetime(final_data['DateTillMaintain_comp3'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "final_data ['RULtillMaintain_comp4'] = (pandas.to_datetime(final_data['DateTillMaintain_comp4'])- pandas.to_datetime(final_data['datetime'])).astype('timedelta64[h]')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration',\n",
       "       'model', 'age', 'error4', 'error3', 'error2', 'error1', 'Mantain_comp4',\n",
       "       'Mantain_comp3', 'Mantain_comp2', 'Mantain_comp1', 'fail_comp4',\n",
       "       'fail_comp3', 'fail_comp2', 'fail_comp1', 'DateTillMaintain_comp1',\n",
       "       'DateTillMaintain_comp2', 'DateTillMaintain_comp3',\n",
       "       'DateTillMaintain_comp4', 'DateTillFailure_comp1',\n",
       "       'DateTillFailure_comp2', 'DateTillFailure_comp3',\n",
       "       'DateTillFailure_comp4', 'RULtillFail_comp1', 'RULtillFail_comp2',\n",
       "       'RULtillFail_comp3', 'RULtillFail_comp4', 'RULtillMaintain_comp1',\n",
       "       'RULtillMaintain_comp2', 'RULtillMaintain_comp3',\n",
       "       'RULtillMaintain_comp4', 'comp1_1stwarning', 'comp2_1stwarning',\n",
       "       'comp3_1stwarning', 'comp4_1stwarning', 'comp1_2ndwarning',\n",
       "       'comp2_2ndwarning', 'comp3_2ndwarning', 'comp4_2ndwarning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('predictors_sql_data.csv', sep = ',',encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration',\n",
       "       'model', 'age', 'error4', 'error3', 'error2', 'error1', 'Mantain_comp4',\n",
       "       'Mantain_comp3', 'Mantain_comp2', 'Mantain_comp1', 'fail_comp4',\n",
       "       'fail_comp3', 'fail_comp2', 'fail_comp1', 'DateTillMaintain_comp1',\n",
       "       'DateTillMaintain_comp2', 'DateTillMaintain_comp3',\n",
       "       'DateTillMaintain_comp4', 'DateTillFailure_comp1',\n",
       "       'DateTillFailure_comp2', 'DateTillFailure_comp3',\n",
       "       'DateTillFailure_comp4', 'RULtillFail_comp1', 'RULtillFail_comp2',\n",
       "       'RULtillFail_comp3', 'RULtillFail_comp4', 'RULtillMaintain_comp1',\n",
       "       'RULtillMaintain_comp2', 'RULtillMaintain_comp3',\n",
       "       'RULtillMaintain_comp4', 'comp1_1stwarning', 'comp2_1stwarning',\n",
       "       'comp3_1stwarning', 'comp4_1stwarning', 'comp1_2ndwarning',\n",
       "       'comp2_2ndwarning', 'comp3_2ndwarning', 'comp4_2ndwarning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 30\n",
    "w0 = 15\n",
    "final_data['comp1_1stwarning'] = numpy.where(final_data['RULtillFail_comp1'] <= w1, 1, 0 )\n",
    "final_data['comp2_1stwarning'] = numpy.where(final_data['RULtillFail_comp2'] <= w1, 1, 0 )\n",
    "final_data['comp3_1stwarning'] = numpy.where(final_data['RULtillFail_comp3'] <= w1, 1, 0 )\n",
    "final_data['comp4_1stwarning'] = numpy.where(final_data['RULtillFail_comp4'] <= w1, 1, 0 )\n",
    "final_data['comp1_2ndwarning'] = final_data['comp1_1stwarning']\n",
    "final_data['comp2_2ndwarning'] = final_data['comp2_1stwarning']\n",
    "final_data['comp3_2ndwarning'] = final_data['comp3_1stwarning']\n",
    "final_data['comp4_2ndwarning'] = final_data['comp4_1stwarning']\n",
    "\n",
    "\n",
    "final_data.loc[final_data['RULtillFail_comp1'] <= w0, 'comp1_2ndwarning'] = 2\n",
    "final_data.loc[final_data['RULtillFail_comp2'] <= w0, 'comp2_2ndwarning'] = 2\n",
    "final_data.loc[final_data['RULtillFail_comp3'] <= w0, 'comp3_2ndwarning'] = 2\n",
    "final_data.loc[final_data['RULtillFail_comp4'] <= w0, 'comp4_2ndwarning'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                  2014-06-01 06:00:00\n",
       "machineID                                   1\n",
       "volt                                        0\n",
       "rotate                                      0\n",
       "pressure                                    0\n",
       "vibration                                   0\n",
       "model                                       0\n",
       "age                                         0\n",
       "error4                                      0\n",
       "error3                                      0\n",
       "error2                                      0\n",
       "error1                                      0\n",
       "Mantain_comp4                               0\n",
       "Mantain_comp3                               0\n",
       "Mantain_comp2                               0\n",
       "Mantain_comp1                               0\n",
       "fail_comp4                                  0\n",
       "fail_comp3                                  0\n",
       "fail_comp2                                  0\n",
       "fail_comp1                                  0\n",
       "DateTillMaintain_comp1    2014-06-01 06:00:00\n",
       "RULtillFail_comp1                           0\n",
       "RULtillFail_comp2                           0\n",
       "RULtillFail_comp3                           0\n",
       "RULtillFail_comp4                           0\n",
       "RULtillMaintain_comp1                       0\n",
       "RULtillMaintain_comp2                       0\n",
       "RULtillMaintain_comp3                       0\n",
       "RULtillMaintain_comp4                       0\n",
       "comp1_1stwarning                            0\n",
       "comp2_1stwarning                            0\n",
       "comp3_1stwarning                            0\n",
       "comp4_1stwarning                            0\n",
       "comp1_2ndwarning                            0\n",
       "comp2_2ndwarning                            0\n",
       "comp3_2ndwarning                            0\n",
       "comp4_2ndwarning                            0\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime                  8764644\n",
       "machineID                 8764644\n",
       "volt                      8764644\n",
       "rotate                    8764644\n",
       "pressure                  8764644\n",
       "vibration                 8764644\n",
       "model                     8764644\n",
       "age                       8764644\n",
       "error4                    8764644\n",
       "error3                    8764644\n",
       "error2                    8764644\n",
       "error1                    8764644\n",
       "Mantain_comp4             8764644\n",
       "Mantain_comp3             8764644\n",
       "Mantain_comp2             8764644\n",
       "Mantain_comp1             8764644\n",
       "fail_comp4                8764644\n",
       "fail_comp3                8764644\n",
       "fail_comp2                8764644\n",
       "fail_comp1                8764644\n",
       "DateTillMaintain_comp1    8764644\n",
       "DateTillMaintain_comp2    8764603\n",
       "DateTillMaintain_comp3    8764603\n",
       "DateTillMaintain_comp4    8764585\n",
       "DateTillFailure_comp1     8740280\n",
       "DateTillFailure_comp2     8740528\n",
       "DateTillFailure_comp3     8740614\n",
       "DateTillFailure_comp4     8740267\n",
       "RULtillFail_comp1         8740280\n",
       "RULtillFail_comp2         8740528\n",
       "RULtillFail_comp3         8740614\n",
       "RULtillFail_comp4         8740267\n",
       "RULtillMaintain_comp1     8764644\n",
       "RULtillMaintain_comp2     8764603\n",
       "RULtillMaintain_comp3     8764603\n",
       "RULtillMaintain_comp4     8764585\n",
       "comp1_1stwarning          8764644\n",
       "comp2_1stwarning          8764644\n",
       "comp3_1stwarning          8764644\n",
       "comp4_1stwarning          8764644\n",
       "comp1_2ndwarning          8764644\n",
       "comp2_2ndwarning          8764644\n",
       "comp3_2ndwarning          8764644\n",
       "comp4_2ndwarning          8764644\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>DateTillMaintain_comp1</th>\n",
       "      <th>DateTillMaintain_comp2</th>\n",
       "      <th>DateTillMaintain_comp3</th>\n",
       "      <th>DateTillMaintain_comp4</th>\n",
       "      <th>DateTillFailure_comp1</th>\n",
       "      <th>DateTillFailure_comp2</th>\n",
       "      <th>DateTillFailure_comp3</th>\n",
       "      <th>DateTillFailure_comp4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [datetime, DateTillMaintain_comp1, DateTillMaintain_comp2, DateTillMaintain_comp3, DateTillMaintain_comp4, DateTillFailure_comp1, DateTillFailure_comp2, DateTillFailure_comp3, DateTillFailure_comp4]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.loc[(final_data['RULtillFail_comp1'])<0, ['datetime','DateTillMaintain_comp1',\n",
    "       'DateTillMaintain_comp2', 'DateTillMaintain_comp3',\n",
    "       'DateTillMaintain_comp4', 'DateTillFailure_comp1',\n",
    "       'DateTillFailure_comp2', 'DateTillFailure_comp3',\n",
    "       'DateTillFailure_comp4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_data=final_data.loc[final_data['volt']>0]\n",
    "final_data = final_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration',\n",
       "       'model', 'age', 'error4', 'error3', 'error2', 'error1', 'Mantain_comp4',\n",
       "       'Mantain_comp3', 'Mantain_comp2', 'Mantain_comp1', 'fail_comp4',\n",
       "       'fail_comp3', 'fail_comp2', 'fail_comp1', 'DateTillMaintain_comp1',\n",
       "       'DateTillMaintain_comp2', 'DateTillMaintain_comp3',\n",
       "       'DateTillMaintain_comp4', 'DateTillFailure_comp1',\n",
       "       'DateTillFailure_comp2', 'DateTillFailure_comp3',\n",
       "       'DateTillFailure_comp4', 'RULtillFail_comp1', 'RULtillFail_comp2',\n",
       "       'RULtillFail_comp3', 'RULtillFail_comp4', 'RULtillMaintain_comp1',\n",
       "       'RULtillMaintain_comp2', 'RULtillMaintain_comp3',\n",
       "       'RULtillMaintain_comp4', 'comp1_1stwarning', 'comp2_1stwarning',\n",
       "       'comp3_1stwarning', 'comp4_1stwarning', 'comp1_2ndwarning',\n",
       "       'comp2_2ndwarning', 'comp3_2ndwarning', 'comp4_2ndwarning'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols =['datetime', 'machineID', 'volt', 'rotate', 'pressure', 'vibration',\n",
    "       'model', 'age', 'error4', 'error3', 'error2', 'error1', 'Mantain_comp4',\n",
    "       'Mantain_comp3', 'Mantain_comp2', 'Mantain_comp1', 'fail_comp4',\n",
    "       'fail_comp3', 'fail_comp2', 'fail_comp1','RULtillFail_comp1', 'RULtillFail_comp2',\n",
    "       'RULtillFail_comp3', 'RULtillFail_comp4', 'RULtillMaintain_comp1',\n",
    "       'RULtillMaintain_comp2', 'RULtillMaintain_comp3',\n",
    "       'RULtillMaintain_comp4', 'comp1_1stwarning', 'comp2_1stwarning',\n",
    "       'comp3_1stwarning', 'comp4_1stwarning', 'comp1_2ndwarning',\n",
    "       'comp2_2ndwarning', 'comp3_2ndwarning', 'comp4_2ndwarning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = final_data.loc[(final_data['datetime'])<'2015-08-01',cols ]\n",
    "test_data = final_data.loc[(final_data['datetime'])>='2015-08-01',cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_normalize = train_data.columns.difference(['datetime','machineID','model','RULtillFail_comp1', 'RULtillFail_comp2',\n",
    "       'RULtillFail_comp3', 'RULtillFail_comp4', 'RULtillMaintain_comp1',\n",
    "       'RULtillMaintain_comp2', 'RULtillMaintain_comp3',\n",
    "       'RULtillMaintain_comp4','comp1_1stwarning', 'comp2_1stwarning',\n",
    "       'comp3_1stwarning', 'comp4_1stwarning', 'comp1_2ndwarning',\n",
    "       'comp2_2ndwarning', 'comp3_2ndwarning', 'comp4_2ndwarning'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pandas.DataFrame(min_max_scaler.fit_transform(train_data[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_data.index)\n",
    "join_df = train_data[train_data.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_data = join_df.reindex(columns = train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_test_df = pandas.DataFrame(min_max_scaler.transform(test_data[cols_normalize]), \n",
    "                            columns=cols_normalize, \n",
    "                            index=test_data.index)\n",
    "test_join_df = test_data[test_data.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "test_data = test_join_df.reindex(columns = test_data.columns)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a large window size of 50 cycles\n",
    "sequence_length = 50\n",
    "\n",
    "# function to reshape features into (samples, time steps, features) \n",
    "def gen_sequence(id_df, seq_length, seq_cols):\n",
    "    \"\"\" Only sequences that meet the window-length are considered, no padding is used. This means for testing\n",
    "    we need to drop those which are below the window-length. An alternative would be to pad sequences so that\n",
    "    we can use shorter ones \"\"\"\n",
    "    # for one id I put all the rows in a single matrix\n",
    "    data_matrix = id_df[seq_cols].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # Iterate over two lists in parallel.\n",
    "    # For example id1 have 192 rows and sequence_length is equal to 50\n",
    "    # so zip iterate over two following list of numbers (0,112),(50,192)\n",
    "    # 0 50 -> from row 0 to row 50\n",
    "    # 1 51 -> from row 1 to row 51\n",
    "    # 2 52 -> from row 2 to row 52\n",
    "    # ...\n",
    "    # 111 191 -> from row 111 to 191\n",
    "    for start, stop in zip(range(0, num_elements-seq_length), range(seq_length, num_elements)):\n",
    "        yield data_matrix[start:stop, :]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_cols = ['volt', 'rotate', 'pressure', 'vibration', 'age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_gen = (list(gen_sequence(train_data[train_data['machineID']==id], sequence_length, sequence_cols)) \n",
    "           for id in train_data['machineID'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5032000, 50, 5)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_array = numpy.concatenate(list(seq_gen)).astype(numpy.float32)\n",
    "seq_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_labels(id_df, seq_length, label):\n",
    "    # For one id I put all the labels in a single matrix.\n",
    "    # For example:\n",
    "    # [[1]\n",
    "    # [4]\n",
    "    # [1]\n",
    "    # [5]\n",
    "    # [9]\n",
    "    # ...\n",
    "    # [200]] \n",
    "    data_matrix = id_df[label].values\n",
    "    num_elements = data_matrix.shape[0]\n",
    "    # I have to remove the first seq_length labels\n",
    "    # because for one id the first sequence of seq_length size have as target\n",
    "    # the last label (the previus ones are discarded).\n",
    "    # All the next id's sequences will have associated step by step one label as target. \n",
    "    return data_matrix[seq_length:num_elements, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5032000, 1)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate labels\n",
    "label_gen = [gen_labels(train_data[train_data['machineID']==id], sequence_length, ['comp1_1stwarning']) \n",
    "             for id in train_data['machineID'].unique()]\n",
    "label_array = numpy.concatenate(label_gen).astype(numpy.float32)\n",
    "label_array.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 50, 100)           42400     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 50, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 50)                30200     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 72,651\n",
      "Trainable params: 72,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_path = 'binary_model.h5'\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "         input_shape=(sequence_length, nb_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "# fit the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4780400 samples, validate on 251600 samples\n",
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(seq_array, label_array, epochs=100, batch_size=200, validation_split=0.05, verbose=2,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='min'),\n",
    "                       keras.callbacks.ModelCheckpoint(model_path,monitor='val_loss', save_best_only=True, mode='min', verbose=0)]\n",
    "          )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "\n",
    "# summarize history for Accuracy\n",
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "fig_acc.savefig(\"model_accuracy.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_acc = plt.figure(figsize=(10, 10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "fig_acc.savefig(\"model_loss.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training metrics\n",
    "scores = model.evaluate(seq_array, label_array, verbose=1, batch_size=200)\n",
    "print('Accurracy: {}'.format(scores[1]))\n",
    "\n",
    "# make predictions and compute confusion matrix\n",
    "y_pred = model.predict_classes(seq_array,verbose=1, batch_size=200)\n",
    "y_true = label_array\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
